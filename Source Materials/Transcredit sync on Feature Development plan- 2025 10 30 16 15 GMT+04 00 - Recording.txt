(Transcribed by TurboScribe.ai. Go Unlimited to remove this message.)

[Speaker 1] (0:09 - 2:35)
Я ему скинул ссылочку, написал сообщение. Ладно, в общем, смотрите, тут есть несколько моментов. Значит, два основных момента, которые меня...

Ладно, три момента, которые меня сейчас интересуют. Первый – это OCR, второй – это генерация документов, и третий – это email server. Значит, про OCR.

Значит, изначально ОКОП там в презентации его как бы... Ну, в общем, мы когда с ОКОПом разговаривали, только потом как бы поняли, что OCR, он действительно озвучивал, что есть какая-то наработка по OCR для того, чтобы в документ менеджмент сервисе обрабатывать вот эти файлы, и потом, соответственно, они попадали уже в базу не как документы, а как уже какие-то объекты. Значит, это, наверное, самый большой вопрос, потому что если OCR делать не нужно, то таймлайны очень сильно сократятся.

Если же OCR делать нужно с нуля, например, то это будет, наверное, самая большая часть работы в этом проекте. То есть надо будет сначала сделать механизм, который будет позволять в отдельном пайплайне, то есть в отдельном сервисе забирать документы, их обрабатывать и потом, соответственно, сохранять их в базу. Если же сервис, который у них есть, и мы сегодня по коду копайлотом, я попросил Артема посмотреть, в коде, в репозитории есть упоминание OCR, и там даже есть какой-то OCR replacement service, который вроде как делает исправление после того, как OCR, то есть автоматические исправления после того, как OCR отработал.

И это я написал там вопросы, есть вторая вкладочка Q&A, и там есть вопросики по OCR как раз таки. Вот их можно было бы задать Эйману, то есть они нам в целом просто помогут. Я не вижу смысла делать с ними звонок, голосом это проговаривать, потому что в прошлый раз, когда мы с ним проговаривали вопросы, я не сказал бы, что сильно много каких-то дополнительных деталей мы для себя прояснили, поэтому Эйману можно просто дать эти вопросы, чтобы он на них кратенько ответил.

Он может просто лум записать, голосом по ним пройтись, может текстом ответить.

[Speaker 4] (2:36 - 2:43)
Давай прямо сейчас закину Эйману в чате Transcredit вот эти вопросы, и тегну, чтобы он просто ответил на каждое из них.

[Speaker 1] (2:43 - 8:06)
Да, пожалуйста, так будет даже проще. Значит, по стеку технологиям, по репозиторию, по процессу диплоймента вообще ничего не меняется, потому что у них один большой монолеп, в котором проекты и все компоненты остаются, стилизация также не меняется, подход к публичной части также не меняется. По диплойменту тоже ничего не меняется, остается стандартная концепция, как и везде.

Ну я так, по крайней мере, предполагаю, потому что во всех проектах, что было, остался пайплайн один и тот же. Соответственно состав команды примерно такой же, то есть практически все on-demand, либо shareable, кроме бизнес-аналитика, скорее всего, и девелопера. Будем смотреть по таймлайну, сколько сюда человек поставит, но вполне возможно, что сюда надо будет двоих, как минимум, как и на agent service.

А вот Апаш подключился. Я правду, Ваня, наверное, написал? Я попросил, да, Апаш.

А, окей. Хорошо. Так, по аутентификации у нас здесь то же самое остается, как и было.

Роли мы никакие не добавляем. Их, соответственно, admin directory, те группы, которые там есть в ажуре, они остаются, просто там будут добавляться настройки по permission для доступа к этим страницам. То же самое в dmz, публичной части.

У нас остается аутентификация, как и была во всем приложении, так и в приложении с аутентификацией уже есть. Скорее всего, там просто появится новый раздел, и все. Значит, из того, что admin сделал сейчас, по dmz-части он ничего не добавлял.

То есть там как раз-таки основной вот этой страницы, где можно, соответственно, загружать документы, или вообще в целом их обрабатывать, ее нет. Вот. Так, что у нас из интеграции?

Значит, из интеграции у нас вот этот OCR-сервис, doc-management-сервис с OCR. Это то, что, соответственно, мы сейчас в вопросе проясним, есть ли он у них и насколько мы можем его переиспользовать, чтобы понимать, не придется ли нам его с нуля делать. Если придется делать с нуля, то, возможно, мы просто воспользуемся API-шкой, готовой в Майкрософте.

Там есть, соответственно, OCR-сервис для таких же как раз-таки вещей, как insurance healthcare, уже умеет работать с формами, дает структурированный вывод с неплохим качеством. Но, скорее всего, эта штука будет платная, и она, соответственно, ну, надо подумать, готовы ли они за нее платить. Если же нет, то надо будет возвращаться к наработкам нашего R&D и поднимать, что они уже там делали.

Только тут не будет времени на разметку. Дальше. Да, как раз Ваня может нам ответить.

По internal sync стандартный flow, то есть нет прямой связи между публичной стороной и стороной основной плато. Соответственно, есть Ops log. Да, сейчас, секунду.

Значит, есть этот Ops log, в который мы закидываем какие-то события, и они заставляют, соответственно, делать выборки из одной базы либо из другой базы. То есть такую промежуточную синхронизацию. И есть email-сервис тоже.

Значит, с учетом того, что Amon сделал вот эту страничку, я так понимаю, что они хотят все-таки делать email-коммуникацию, а не коммуникацию через модификацию, как мы и предполагали. Возможно, тут стоит подойти с такой стороны, что мы можем сделать, так как все-таки быстрее, скорее всего, будет сделать internal-коммуникацию, то есть через базу, через наш вот этот Ops log, а не делать через email-сервис. А email-сервис оцените сделать потом, потому что там я разговаривал с Артемом, он напрямую так не делал, но вроде как у Амазоновских, у Амазона есть, соответственно, что-то типа лямбда-функции, которые могут слушать email-сервис, который, так как они все равно используют их внутренний Microsoft 365 с МТП, то вроде как он может слушать входящие письма, и XML, который получается внутри, он может его обрабатывать и, соответственно, передавать куда-то уже, как serverless, такую функцию. Но это вопрос, я с таким не сталкивался и не работал. Может быть, Паша про это что-то знает, но я бы, наверное, оставил все-таки email-сервис на потом.

Но когда у нас нет экрана именно с коммуникацией с письмами, либо мы можем оставить как условно какой-то один почтовый ящик, который будет, как и сейчас, они получают письма, но тогда у нас не будет механизма обработки документов. Это по-хорошему надо как-то вынести, может быть, аутоскоп, либо там фаза 3, или просто в процессе это додумывать. Вот.

Пока все. Давайте, наверное, Акоп. Ты по-всякому можешь что-то сказать.

[Speaker 2] (8:08 - 8:27)
Да, я просто написал, если будете задавать вопрос, уточните лучше, в том числе, нет ли у них уже предвыбранных продуктов, которые они хотят интегрировать, чтобы нам просто не делать лишнюю работу, не искать решения, создавать матрицу сравнения, предлагать им, не знаю.

[Speaker 1] (8:28 - 8:31)
Ты о чем? Продуктов, которые, если у них нет...

[Speaker 2] (8:31 - 8:35)
Мы же не будем с нуля писать нейронку, правильно, по компьютеру?

[Speaker 1] (8:35 - 9:42)
Нет, так уже есть. Мы уже сделали, мы даже, по-моему, оффер делали по OCR изначально. Там был целый сервис, который, соответственно, Q&A-инструмент, в котором ты мог видеть, что у тебя в документе, и что тебе отдала моделька.

Мы использовали гугловский OCR, просто API, но, возможно, они его не захотят. Но есть точно такой же, только Microsoft. То есть там тоже API, ты фактически то же самое делаешь, ты передаешь туда в Base64 документ, он тебе его партнит, и возвращает JSON, в котором есть объект с полями, который он вытянул из него, то есть ключ значения, и в каждом ключе есть еще confident значение от 0 до 1, и это зависит от того, насколько он уверен в полученном значении, вот в этом value.

Тут вопрос к Ване. Вань, скажи, ты с ними общался. Скажи, у них есть уже OCR или нет?

[Speaker 3] (9:42 - 10:03)
Ты что-нибудь про это знаешь? Я знаю достаточно мало. Я знаю, что Tender выиграла какая-то определенная контора, соответственно, своего OCR у них нет.

Это вот тема того, когда мы им пытались что-то предоставить свое, но у них все на этапе POC было, когда я ездил. То есть на продакшене у них ничего нет.

[Speaker 1] (10:05 - 13:14)
Короче, это надо будет спрашивать. Просто смотри, получается так, что если у них какой-то вендор сейчас делает концепт по OCR, какой смысл нам в этом проекте делать параллельно ту же самую работу? Я не вижу в этом никакого смысла.

То есть я тогда не понимаю. Этот вопрос надо уточнять. Если он скажет, что есть хотя бы какой-то базовый концепт, который мы можем использовать, это уже хорошо, потому что мы бы тогда просто заиспользовали бы его, какой-то базовый API, который уже с этим может делать, и параллельно ждали бы завершение.

То есть завершение нашей части частично или полностью бы зависело от завершения этого OCR-модуля. Что тут еще? Я, наверное, с большего все рассказал по фичер-листу.

По фичер-листу, что я выделил в задаче? Сертификационный портал публичный, то, что он может сделать. То есть это портал, на котором агенты могут, соответственно, создавать эти репорты, загружать туда сертификаты.

Каждый сертификат будет иметь, в частности, репорт, будет иметь какой-то статус. Как только мы его сабмитим, то, соответственно, репорт попадает во внутреннюю базу DMZ, и в OpsLog отдается event, что он, соответственно, готов к верификации. Далее, соответственно, этот репорт забирается этим нашим или не нашим OCR-энжином, обрабатывается.

Тут, так как они учитывали, точнее, Эйман говорил про документ менеджмент с OCR, пайплайном, который у них есть, этот пайплайн забирает документы, обрабатывает их, соответственно, и дальше вопрос. Значит, касательно OCR, есть проблема в том, что мы не можем на 100% гарантировать, что он отдает данные так, как они... Короче, он не может на 100% отдать корректные данные.

Скорее всего, какие-то поля, в случае нечитаемого текста, либо, возможно, ключ значения неправильно подобрало, он будет отдавать с низким значением confident 0.5 или 0.4, или вообще не распознает. То для этого есть обычно, если, Ваня, помнишь, мы, когда делали наш прототип, мы делали этот QA-ревью-экран. То есть там, где экран сравнения, и оно тебе показывает, что confident такой-то, уверен, и если ты там, соответственно, видишь какие-то расхождения, ты просто руками корректируешь и нажимаешь confirm.

И вот, соответственно, в этом флоу, как мне кажется, так или иначе, все равно должен быть какой-то такой процесс. То есть я его сюда вынес вот таким серым, что как не обязательно, но мне кажется, что эта штука в любом случае должна быть, так как есть OCR. Что думаете?

Ну и, я так понимаю, Акоб сказал да. Ваня на мьюте.

[Speaker 3] (13:15 - 13:30)
Я пытаюсь, я прошу прощения, если я глупые вопросы задаю, я пытаюсь догнать паровоз. Мы точно должны OCR здесь делать? Я вот прошу прощения, у меня пока не складывалось впечатление до сегодняшнего момента.

Акоб, мы с тобой общались, там, по-моему, не было OCR.

[Speaker 2] (13:30 - 14:31)
Да, смотри, короткая история, как сложилось. То предложение, которое мы с тобой обсуждали, то, которое ты сформировал, они, когда послушали, они такие не-не-не-не-не, там, ну, у нас не может быть такой автоматизации, потому что со стороны агента мы не можем ему сказать, типа, вводи те же самые данные, еще одну веб-пьюху. Вот, то есть они уже работают с каким-то интерфейсом, который там от государственных каких-то органов.

Вот, то есть они туда вводят все эти данные по клиентам, потом получается то, что мы с тобой предлагаем, это агенту еще раз вводить данные самому руками, чтобы избежать всех этих ошибок, которые они избегают. Поэтому они говорят, мы такое не можем себе позволить, поэтому мы работаем, как мы работали, но для автоматизации мы будем использовать OCR. То есть, да, агент также отправляет документы, как он сейчас отправляет.

Просто теперь мы будем работать не сами ручками, открывать каждый документ и вводить вручную эти поля, а это будет делать OCR. Вот.

[Speaker 3] (14:31 - 14:36)
И спасибо за это, потому что я качественно отстал от этого.

[Speaker 1] (14:36 - 14:47)
Тут, Вань, получается смысл такой, что на последнем звонке они говорили, что в целом вот этих вот сертификатов, которые им присылают, минимум на каждый штат своя.

[Speaker 5] (14:47 - 14:47)
Да.

[Speaker 1] (14:47 - 16:11)
И также может быть, что в рамках одного штата может быть еще несколько разных типов форм. То есть документ не строго стандартизирован. И даже если бы мы переходили на какую-то унифицированную форму, просто именно веб-вьюху, то тут есть проблема унификации этой формы для всех штатов, для всех продуктов.

И второй момент – это необходимость заполнения всех этих данных на стороне агента. То есть, если, например, им нужно отправить десяток форм, то им надо, соответственно, переписать ручками десять раз в нашей вот этой вот UI, что в целом не очень удобно. Если мы говорили про agent-сервис, там, где форма заполняется всего один раз, если она небольшая, то это несложно.

Но когда мы говорим про вот такие репорты и сертификаты, то это практически нереально так сделать. И мало того, там даже поднимался такой вопрос, что, скорее всего, некоторые агенты в любом случае не будут использовать для загрузки этих сертификатов веб-вьюх. Скорее всего, они так или иначе будут продолжать отправлять это на почтовый ад.

Поэтому email-сервер тоже вроде как must-have в данном случае. Но это надо просто чуть попозже, как такой небольшой assumption, что это менее вероятная проблема. Или не самая важная проблема для данного случая.

[Speaker 3] (16:12 - 16:35)
Ясно. Спасибо. Я буквально на минутку встряну и дам обратное слово.

Тогда стопроц валидный комментарий на тему того, зачем с нуля пилить UCR, если у них был уже вендор, и пока не ясно, будет ли их решение использоваться здесь или нет, стопроц. Второе, CRQR VUI это классная фича, которая, да, лайк-лайк 100% на оба комментария.

[Speaker 1] (16:35 - 20:18)
Да, тогда у нас получается, что мы берем вот этот OCR engine, сейчас получим ответ, есть он или его нет. Если его нет, то, скорее всего, мы будем переиспользовать уже просто опишку до того момента, пока не появится их внутренний какой-то OCR engine. Опишку мы уже точно знаем, что гугловский 100% рабочий, возможно, майкрософтовский также можно переиспользовать.

Гугловский абсолютно простой, удобный, один endpoint, передал документ или картинку, получил объект с Confident. Все просто и удобно. По CRQR VUI нету какого-то концепта, дизайн-концепта или макапа, но в целом ничего сложного нет.

Он там показывал страничку, где у тебя справа документ, слева формочка. Форма не структурированная, просто в виде ключ-значения, последовательно, как мы видим в документе. Не так, как мы делали красиво, что у нас там прям отрисовывается документ в тех же положениях.

Я думаю, это не имеет никакого смысла. Просто структурированный документ, как бы поле под полем. Дальше.

Это, получается, по CRQR VUI. Дальше, соответственно, импорт документов. Значит, эта часть просто как отдельная фича.

Сюда вынесли оценки для того, чтобы... Ну, то есть у нас база распределена таким образом, что после того, как CR отработал, он записывает, соответственно, поля, прикрепленные для документов. Но это еще не готовый сертификат.

Он как бы еще не опробован. Поэтому только после того, как он проходит Q&A-ревью со стороны оператора, и он нажимает типа «Подтвердить», что все поля внесены правильно, то тогда мы, получается, уже формируем непосредственно сертификат. И вот этот сертификат уже у нас начинает проходить валидацию.

Потому что технически, если мы поставили бы этот процесс до Q&A UI, то валидация могла бы падать только из-за того, что мы неправильно преобразовали какие-то поля из документов. Вот поэтому в такой именно последовательности. Значит, по сёрчу это просто UINS оставляющая.

Есть страничка, на которой видны все эти сертификаты. И они просто хотят добавить чуть больше полей, по которым можно искать эти сертификаты. Вот этот error checking, как раз таки автоматизация, то, что я сказал после вот этой части, после импорта.

Значит, у них сейчас есть логика валидации этих документов в Аксессе. И она нигде не прописана. Ее AIMON не переносил, никакой информации по ней не давал.

Сколько ее там тоже пока непонятно. И как она реализована, непонятно. То есть это просто как задача, которую нужно будет, не знаю, теоретически оценить какое-то количество времени по переносу логики валидации этих документов, сертификата.

Тут, наверное, ваш какой-то комментарий хорошо получить. Будем ли мы это закидывать в пропозал, или мы это вынесем как assumption, что это рискованная часть или просто в риске даже. Не то, что в assumption, а скорее в риске, что мы не знаем объем работы по этой валидации за счет того, что она есть, она готова, реализована.

Но нам ее нужно просто перенести, понять и перенести.

[Speaker 4] (20:21 - 20:46)
Я бы заказал, что будет написано с нуля. Я бы время закладывал, что если логику невозможно использовать. Хорошо, что если возможно использовать.

То есть assumption, что мы закладывали вот этот функциональный блок, логика будет писаться с нуля. Если ее можно будет переиспользовать, то время будет, естественно, reduced. Да, Коба?

[Speaker 2] (20:49 - 21:41)
Да, я согласен. И просто надо понимать, что значит с нуля. В любом случае с IC-шарпой у них этого нет, по-любому он будет писать с нуля.

А если у нас алгоритмы вот этих бизнес-правил, это другой вопрос. Просто, я думаю, очень сильная зависимость от клиента, потому что аналитик, который будет там описывать это все для разработчика, по каким бизнес-правилам тут валидации проводить, он должен будет очень тесно и часто общаться со стороной клиента. И, возможно, даже с разработчиком на их стороне, который из VBA скриптов будет доставать всю эту логику и рассказывать, как это проходит.

Ну, то есть, я не знаю, может быть, они нам дадут доступ к этому ко всему, и тогда наш разработчик будет вместе с аналитиком копаться в этом. Ну, то есть тут, мне кажется, самая такая скрупулезная и сложная история будет с точки зрения трудозатрат.

[Speaker 4] (21:42 - 21:48)
Ну, я бы, да, докладывал с нуля. Полностью нет ничего. Удастся что-то переиспользовать?

Круто.

[Speaker 1] (21:48 - 25:09)
Мы тут ничего оставляем, потому что она в целом важна для проекта, как валидация ошибок. Но при этом закладывал на нее по большему времени, потому что она достаточно рисковая. Мы не знаем, какой конкретно объем работы там сейчас есть и насколько реалистично использовать уже те наработки, которые у них есть.

Так, с этим понятно. Дальше, error summary UI. Здесь фактически это просто, так как валидация идет автоматическая, то нам нужен какой-то интерфейс, который в рамках сертификата покажет, какие ошибки там были.

Вот. Соответственно, этот error summary UI, это просто будет на странице детали сертификата, как отдельная секция. Я ее, по крайней мере, так представляю, в которой будет написано, что конкретно там не прошло валидацию.

И технически вот эти ошибки, которые там прошли, мы должны отправить агенту в виде письма. Как раз таки, то есть там должна быть вот эта интеграция с нотификацией. Вот она здесь вот есть.

Которая... чуть ниже. Которая, соответственно, позволит им передавать эту нотификацию.

То есть нотификацию мы можем двумя путями передавать. Письмом просто отправить им письмо с эффектом ошибки или в виде документа. И второй момент.

Мы можем отправить им письмо через как бы база-то-база, через обслог этот в DMZ, и он у них в портале просто отобразится, что нужны коррекции. А как коррекции происходят, там у меня было вначале описано, вот editing-форма вот эта, в которой если там есть ошибки в каких-то конкретных полях, то есть так как все равно документ уже был распознан, верифицирован и распознан, то мы можем им уже отдать в виде каких-то полей, которые, соответственно, попросить исправить. Вот.

Это, наверное, самый такой важный момент, потому что если поле уже было верифицировано, и мы дадим возможность агентам перезаполнять все поля с нуля каждый раз, то нам фактически каждый раз нужно делать верификацию всего документа. А если мы будем делать, к примеру, там, не знаю, дата рождения указана была неправильная, то мы, увидев эту ошибку, отправляем, соответственно, сертификат, в котором все поля дизейбл, кроме, соответственно, даты рождения. И он только ее может исправить, и тогда агенту не придет, точнее, оператору не придется перепроверять весь документ, а только важные поля.

Вот. Значит, есть еще часть вот по balancing модулю, он у Охопа был в to-be пайплайне. Я не до конца понял касательно формирования вот этого баланса, но я так понимаю, что это больше связано с вычислением вот этой суммы, вот этого total, который, соответственно, то есть total всех проданных сертификатов или что-то такое.

Вот. И там есть как раз-таки часть по отправке вот этого репорта или по генерации документа, который вот этот вот баланс и выводит в виде какого-то структурированного отчета. Может, Охоп, ты немножко можешь больше детализировать?

Да.

[Speaker 2] (25:09 - 25:43)
Там история в том, что если расхождения были найдены, какие-то ошибки со стороны агента, то после того, как мы с ним пообщались и о чем-то рассказывал, пришли как бы к единому знаменателю, мы уже заново вводим в систему правильные числа. Разницы там все выплачиваются, возвращаются клиенту, что-то там по coverage снижается, например, и так далее. И уже мы сохраняем окончательные все суммы в системе после вот этого договорения, вот этого балансировка всех этих расхождений.

[Speaker 1] (25:44 - 26:43)
Окей. Ну да, в целом получается так и есть. То есть мы считаем total по всем сертификатам, показываем разницу или формируем коррекцию, которая должна быть в случае, если какие-то были изменения.

Я так понимаю, что они... Как работает это вообще в фин-части, в бухгалтерии? К примеру, если ты выставил invoice, ты не просто берешь и в этом же invoice меняешь сумму.

Для того, чтобы правильно сформировать баланс, и если у тебя invoice был изменен, то ты на этот invoice создаешь коррекцию. Эта коррекция идет отдельным документом, например, с отрицательной или положительной суммой, к примеру. То есть ты выставил invoice на 950, а твой баланс должен быть на тысячу.

То ты создаешь корректирующий invoice на 50, и total у тебя становится по двум invoice уже тысяча. Вот примерно так я это представляю. Не знаю, как это должно правильно у них выглядеть.

[Speaker 2] (26:45 - 27:37)
Там история просто в том, что тот кейс, который она приводила, агенту, например, разрешено продавать на 100 тысяч долларов с покрытием страховых полисов. Если он превысил эти 100 тысяч долларов, и там, на самом деле, куча разветвлений, что с этим можно делать, но не суть. Если он превысил, то они дальше смотрят, а что мы делаем?

Клиенту снижаем вот этот coverage, и тогда мы отправляем уведомления и агенту, и клиенту, что там были внесены изменения, и ваш coverage, например, был вот такой, но вы не можете вот столько, мы вам там снижаем. И приводится это все дальше к балансу. Да, но я думаю, что они клиентам не пишут, они практически пишут клиентам.

Они обязаны. Они даже в прошлый раз нам с тобой сказали, что любые изменения в полисах мы должны по законодательству оповещать клиентам в том числе.

[Speaker 1] (27:38 - 27:45)
Просто это как бы очень странно. Ну ладно, может быть и так. То есть тогда у них должны быть еще контакты к клиентам.

[Speaker 2] (27:46 - 27:52)
Да, смотри, они клиенту пишут, если это аффектит на покрытие и стоимость полиса клиента.

[Speaker 1] (27:53 - 27:57)
Я думал, они уведомляют агента, а агент обязан уведомить клиента.

[Speaker 2] (27:58 - 28:14)
Ну вот нет, они как страховая обязаны, они же вносят по сути. Ну то есть по сути у тебя что получается? Договор-то агент заключил вместе с клиентом, они уже подписали, просто агент ошибся, а страховая уже должна за это все отвечать.

[Speaker 1] (28:18 - 29:33)
Окей, хорошо. По задаче аудита там все в целом понятно. При внесении каких-то изменений в сертификаты мы сохраняем причину изменения, что было изменено, кем, когда.

То есть старое значение, новое, чтобы полностью вот этот вот след изменения оставался в системе. Это нужна будет отдельная таблица у них, этого сейчас нет. Тоже как отдельная задача.

Ну и в целом, наверное, по обслогу, это взаимодействие тоже стандартное, как у нас было в агент сервисе. Тоже промежуточная таблица ивентов, которая позволяет обеим системам просто отслеживать изменения по определенным сущностям. Ну и сертификаты, которые загружаются, наверное, в SharePoint, ShareFiles они используются.

Там храним, как хранилище. Вроде тут ничего не менялось. Вот.

И вот эта задача по ML-серверу, она тоже у меня сейчас как бы not required стоит. Но я так понимаю, что, наверное, она нужна в любом случае будет. Паш, скажи, пожалуйста, ты работал с отслеживанием входящей почты в Azure?

[Speaker 4] (29:40 - 29:44)
А может кто-то... Иначе она не имеет смысла, никакого бизнеса.

[Speaker 1] (29:45 - 29:59)
Ну да, я вот тоже... Я поэтому и говорю, что мне кажется, что ее надо в любом случае оставлять. Значит, у них есть...

Там две, на самом деле, задачи. Сейчас вот этот ML-сервис, он у них работает внутри их... Ну, в общем...

(Second part of meeting, continuous conversation)

[Speaker 1] (0:00 - 1:32)
среды внешней, то есть нельзя использовать их вот этот SMTP протокол за пределом их внутренней почты. Так что, скорее всего, там надо будет либо делать какой-то еще один SMTP протокол наружный, внутри DMZ, который будет получать условно события на отправку уведомлений за пределы их инфраструктуры уже клиентам, а слушать уже, ну, наверное, похожим образом как-то. Вот, email-сервис UI — это то, что ОМОН уже сделал, то есть там уже есть базовый layout, слева менюшка, в которой показаны входящие письма, справа, когда ты кликаешь на письмо, у тебя отображается текст письма, как в любом почтовом клиенте, в Google примерно одинаковый.

Вот, также поиск по теме, распознавание писем происходит по теме письма, то есть в теме письма включается идентификатор какой-то. Когда мы отправляем, например, автоматическое письмо клиенту, мы в теме указываем ID его сертификата, к которому относится это письмо. Соответственно, когда делается реплай, также в теме остается этот идентификатор.

Поэтому мы всегда сможем его вытянуть и, соответственно, найти нужный сертификат, и тело письма или документы, которые в этом письме прикреплены, сможем ассоциировать с определенной записью в пайде.

[Speaker 4] (1:34 - 1:41)
Тема автогенерится или ручками вписывается? Что именно? Тема письма автогенерится или ручками вписывается?

[Speaker 1] (1:41 - 3:08)
Если мы будем отправлять автоматическое письмо, то я думаю, что часть технически может писаться, но приставка темы, этот идентификатор, будет, скорее всего, генерироваться. То есть, к примеру, если мы говорим ошибка в отчете, вот у нас получилась верификация его сертификата, и мы автоматически нашли несколько ошибок. Эти ошибки мы можем записать в письмо, и у нас тема письма будет сертификейт, сертификейт ID, а дальше заголовок этого письма, просто как редактируемое поле, которое оператор может откорректировать или оставить предзаполненное, как оно по дефолту есть, и нажать Submit.

И все, оно ему, соответственно, улетает. Тот нажимает Reply, приходит реплай к нам, так как есть идентификатор в сертификейте ID, то мы его вытаскиваем, ассоциируем с нужным сертификатом и дальше по пайплайну обрабатываем. То есть, валидируем поля, валидируем через QnA UI, и потом дальше уже пробрасываем по процессу.

[Speaker 4] (3:09 - 3:19)
Класс. Я почему спросил? Просто, чтобы исключить, что bottleneck потенциальный, если не будет стягиваться ID, потому что, я так понимаю, это такой костыль, на котором будет весь сервис держаться.

[Speaker 1] (3:20 - 4:21)
К сожалению, если мы говорим про почтовый клиент, они по-другому не работают. Например, если говорить про банковские какие-то детекторы, то есть, к примеру, если ты пользовался банковскими приложениями или, например, электронной бухгалтерией, в которой ты загружаешь invoice или, например, подтверждение транзакции какой-то, например, когда тебе приходит зарплата или то, что ты что-то оплатил, то программа интерпретирует документ по нескольким вещам, по определенному полю, например, transaction details, это transaction title, и смотрит, есть ли у тебя в тайтле идентификатор, нужный, соответственно, или нет.

И по сумме. То есть сумма совпадает или не совпадает. И с письмами то же самое.

Письмо не может быть привязано как сущность к чему-либо. Должен быть связующий элемент либо внутри письма, то есть в теле письма, либо в заголовке. Вот как сам.

[Speaker 2] (4:21 - 4:40)
Через 7 минут MIT по NAP, да, уже к клиентам. Давайте как-то анализироваться. Я все равно не вижу, что…

Эмейл сервер, мы не понимаем концептуально, как мы и что мы будем слушать. Это раз. А как мы будем давать оценку?

Это может быть и 40 часов, и 140 часов.

[Speaker 1] (4:40 - 4:55)
Нет, там ничего сложного нет. Вопрос просто в том, кто с этим работал и может ли дать оценку на это. Вот Артем с этим не работал тоже.

То есть он делал как бы условно пересылку почты.

[Speaker 2] (4:56 - 5:06)
То есть в любом случае, Саша, мы говорим, у нас никто не работал, но это несложно. Есть у нас был такой один проект, у нас ляпнули 40 часов, а делали мы его год потом.

[Speaker 4] (5:06 - 5:07)
Это первое.

[Speaker 2] (5:07 - 5:14)
Мы должны концептуально просто понимать, то есть как мы это можем реализовать.

[Speaker 1] (5:15 - 5:44)
Андрей, так а чего ты ждешь? Если у нас нет человека, который с этим работал, а ты требуешь оценку. Да, DevOps, можно DevOps.

А что DevOps сделает? А что DevOps сделает, если тут не DevOps задача? То есть у нас никто не работал с ML-сервером, но он нужен.

Я его поэтому изначально выделил как optional. То есть изначально мы бы его не делали, мы бы его в пропозал не вставляли, точно так же, как и OCR.

[Speaker 2] (5:44 - 5:51)
Понимание, как его делать, есть вообще? Ну, хотя бы верхнеуровневые. Каких степов он будет состоять?

[Speaker 1] (5:52 - 6:36)
Что надо сделать? Из того, что я поресерчил в публичном доступе, без вообще опыта работы с Azure, то вроде не сложно. Есть два пути, как это можно сделать.

Первый путь – это мы настраиваем в Azure интерфейсе просто листер, который бросает вебхук, как только приходит письмо. Любое входящее письмо будет генерировать вебхук, в котором будет ID письма и все. Следующим мы делаем, используя API, мы получаем это письмо просто через REST обычный.

И в таком случае у нас будет уже, соответственно, вся информация, что в нем, то есть аттачменты, тело письма, заголовок, кому и так далее.

[Speaker 2] (6:37 - 6:39)
Я тут вижу, как есть логика.

[Speaker 1] (6:39 - 6:40)
Окей.

[Speaker 2] (6:40 - 6:55)
И, Саш, ты говорил про то, что у них сейчас в этом. У нас аксессия, да, логика. Это у нас пункт сертификат R-чекинг.

То есть мы не понимаем, какой объем этой логики там.

[Speaker 1] (6:55 - 7:44)
Абсолютно нет. Поэтому вот эта часть должна быть в виде риска либо в assumption. Мы ее тоже не можем оценить.

То есть если мы говорим про другие какие-то задачи, технически мы можем их оценить достаточно точно. Но OCR часть оценить не можем, потому что не знаем, нужно ли писать с нуля, либо переиспользовать то, что есть, либо мы там используем гугловский какой-то API. То есть вообще непонятно.

Далее сертификат R-чекинг тоже не знаем, потому что нет объема. И email сервер тоже в целом не до конца понятно, насколько это будет трудозатратно, потому что у нас никто с этим не работал. Вот.

Три вот эти задачи, они наиболее рискованные в данной оценке. Поэтому они мне были выделены серым, но без них вроде как нельзя.

[Speaker 2] (7:46 - 7:50)
А если они дадут нам доступ к этому аксессу с R-чекингом?

[Speaker 1] (7:50 - 7:53)
Нормально будет? Ну, я не знаю. Это у Паши, наверное, лучше надо спросить.

[Speaker 3] (7:55 - 8:16)
Да, я в целом думал, что все, которые вот эти непонятные задачи, почему бы их не заэсценировать, условно говоря, как какую-то временную многоэстимацию для того, чтобы провести какой-то investigate. Ну, я не знаю, если это так возможно просто. Ну, это же нормально, что мы чего-то не знаем.

И это абсолютно нормально.

[Speaker 1] (8:17 - 8:24)
Но это так и есть. То есть то, что я серым помечаю, это либо как следующая фаза, либо как условный инвестигейт.

[Speaker 3] (8:24 - 8:33)
Задача просто на investigate и все. То есть есть задача на investigate, мы делаем investigate. То есть с того понимания того, сколько это будет занимать.

[Speaker 1] (8:34 - 9:21)
Смотрите, чисто технический объем, количество времени, которое мы потратим на этот проект, для них не сильно важно. Главное, чтобы мы это сделали за максимально короткий срок. При этом мы не можем сделать, соответственно, точную оценку на некоторые части этого приложения, потому что у нас либо нету данных, либо они там не до конца понимают, как это будет работать, либо концепция не до конца ясна.

И мы ее теоретически можем выяснить в процессе уже работы. Поэтому мы можем дать, например, им оценку на все эти задачи, но серые части, которые я здесь опять вернул, как я отмечу, мы дадим оценку условно по 2 дня, то есть примерно по 16 часов. И это будет investigate.

Это экспайки, просто экспайки.

[Speaker 2] (9:22 - 9:51)
То есть, Стас, верно я понимаю, сейчас вопросы, вторая этапа. Нам по-любому нужны ответы на эти вопросы. Я их сейчас закидываю.

Конечно. Отдаем Паше на оценку те технические задачи, вот такой он дотнетчик, просто сколько в спокойном режиме он сделает то, что не серое. А в Prezi мы убираем error checking и убираем email service в именно research, так как сейчас без research по этим блокам мы не можем дать оценку.

[Speaker 1] (9:52 - 10:01)
Да, скорее всего, так не сделаем. У нас будет, получается, feature list deliverables и часть research с дальнейшей реализацией.

[Speaker 2] (10:01 - 10:04)
А риск и assumptions ты добавлять будешь сюда?

[Speaker 1] (10:04 - 10:13)
Тут уже есть, assumptions есть, риск я добавлю, но тут assumptions пока не сильно много, но вот после этого звонка мы немножко их расширим.

[Speaker 2] (10:13 - 10:47)
Хорошо. Итого, я сейчас тогда пойду, Эйману закину вопросы. Так, постараюсь выбить их.

Ты тогда дообновляешь на основании нашего звонка риски. Мы договорились, что серое мы выносим, в Prezi оно прям будет именно, что не out of calls, а типа research phase additional. И будем строить тогда защиту Prezi на основании, так и договорились.

Правильно? Да, думаю, что да. Хорошо, потом туда вопросы спрашивать.

Спасибо. Хорошо.

[Speaker 1] (10:48 - 10:49)
Проделывайте.

[Speaker 3] (10:49 - 10:51)
Все, пока. Пока.

